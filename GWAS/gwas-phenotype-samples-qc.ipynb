{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample QC for GWAS analysis\n",
    "\n",
    "This notebook is delivered \"As-Is\". Notwithstanding anything to the contrary, DNAnexus will have no warranty, support, liability or other obligations with respect to Materials provided hereunder.\n",
    "\n",
    "[MIT License](https://github.com/dnanexus/UKB_RAP/blob/main/LICENSE) applies to this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads cohorts created in cohort browser, perform sample QC and creates file containing phenotype and covariate information needed for GWAS analysis.\n",
    "\n",
    "This work was done mainly by Yih-Chii Hwang, PhD as a part of her work on [AD-by-proxy GWAS Guide](https://dnanexus.gitbook.io/uk-biobank-rap/science-corner/gwas-ex)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyterlab app details (launch configuration)\n",
    "\n",
    "Recommended configuration\n",
    "- runtime: < 10 min\n",
    "- cluster configuration: `Spark cluster`\n",
    "- number of nodes: 2\n",
    "- recommended instance: `mem1_ssd1_v2_x16`\n",
    "- cost: < Â£0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Secify whole exome data (WES) directory, exome field ID, these variables will depend on WES release (e.g. 200K, 300K or 450K) and output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exome_folder = 'Population level exome OQFE variants, PLINK format - interim 200k release'\n",
    "exome_field_id = '23155'\n",
    "output_dir = '/Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Import libraries and initialize Spark connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import databricks.koalas as ks\n",
    "import dxpy\n",
    "import dxdata\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark\n",
    "# Spark initialization (Done only once; do not rerun this cell unless you select Kernel -> Restart kernel).\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load daatset description and select entity containing phenotypic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically discover dispensed dataset ID and load the dataset\n",
    "dispensed_dataset = dxpy.find_one_data_object(\n",
    "    typename=\"Dataset\", \n",
    "    name=\"app*.dataset\", \n",
    "    folder=\"/\", \n",
    "    name_mode=\"glob\")\n",
    "dispensed_dataset_id = dispensed_dataset[\"id\"]\n",
    "dataset = dxdata.load_dataset(id=dispensed_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = dataset['participant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load cohorts that were created in cohort browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = dxdata.load_cohort(\"/Cohorts/diabetes_cases\")  \n",
    "cont = dxdata.load_cohort(\"/Cohorts/diabetes_controls\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Specify fields ID to retrieve, get corresponding UKB RAP field names and print description table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_ids = ['31', '22001', '22006', '22019', '22021', '21022', '41270']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to grab all field names (e.g. \"p<field_id>_iYYY_aZZZ\") of a list of field IDs\n",
    "def fields_for_id(field_id):\n",
    "    from distutils.version import LooseVersion\n",
    "    field_id = str(field_id)\n",
    "    fields = participant.find_fields(name_regex=r'^p{}(_i\\d+)?(_a\\d+)?$'.format(field_id))\n",
    "    return sorted(fields, key=lambda f: LooseVersion(f.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [fields_for_id(f)[0] for f in field_ids] + [participant.find_field(name='p20160_i0')] + [participant.find_field(name='eid')]\n",
    "field_description = pd.DataFrame({\n",
    "    'Field': [f.name for f in fields],\n",
    "    'Title': [f.title for f in fields],\n",
    "    'Coding': [f.coding.codes if f.coding is not None else '' for f in fields ]\n",
    " })\n",
    "field_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Retrieve data for both cohorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_df = participant.retrieve_fields(fields = fields, filter_sql = case.sql, engine=dxdata.connect()).to_koalas()\n",
    "cont_df = participant.retrieve_fields(fields = fields, filter_sql = cont.sql, engine=dxdata.connect(\n",
    "    dialect=\"hive+pyspark\", \n",
    "        connect_args=\n",
    "        {\n",
    "            'config':{'spark.kryoserializer.buffer.max':'256m','spark.sql.autoBroadcastJoinThreshold':'-1'}\n",
    "                     \n",
    "        }\n",
    ")).to_koalas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Create phenotype variable and concatenate cohorts into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_df['diabetes_cc'] = 1\n",
    "cont_df['diabetes_cc'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ks.concat([case_df, cont_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diabetes_cc.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of retrieved data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    |     eid |   p21022 | p41270                                         | p41271   |   p20160_i0 |   p31 |   p22001 |   p22006 |   p22019 |   p22021 |   diabetes_cc |\n",
    "|---:|--------:|---------:|:-----------------------------------------------|:---------|------------:|------:|---------:|---------:|---------:|---------:|--------------:|\n",
    "|  0 | 1234567 |       67 | ['E119', 'M179', 'M431']                       |          |           0 |     0 |      nan |      nan |      nan |      nan |             1 |\n",
    "|  1 | 1234568 |       62 | ['E119', 'R15', 'R32', 'R55', 'Z922']          |          |           0 |     1 |        0 |        1 |      nan |        0 |             1 |\n",
    "|  2 | 1234569 |       50 | ['E119', 'I050', 'I080', 'I10', 'I270']        |          |           1 |     1 |        0 |      nan |      nan |        0 |             0 |\n",
    "|  3 | 1234570 |       60 | ['A099', 'D128', 'D70', 'E114', ]              |          |           1 |     0 |        1 |      nan |      nan |        0 |             0 |\n",
    "|  4 | 1234571 |       58 | ['A082',  'Z867', 'Z948', 'Z960']              |          |           0 |     1 |        1 |        1 |      nan |        0 |             0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. QC samples based on several conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qced = df[\n",
    "    (df['p31'] == df['p22001']) & # Filter in sex and genetic sex are the same           \n",
    "    (df['p22006'] == 1) &         # in_white_british_ancestry_subset           \n",
    "    (df['p22019'].isnull()) &     # Not Sex chromosome aneuploidy           \n",
    "    (df['p22021'] == 0)           # No kinship found\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qced.diabetes_cc.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Rename columns and organize it in format suitable for PLINK and regenie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for better readibility\n",
    "df_qced = df_qced.rename(columns=\n",
    "                         {'eid':'IID', 'p31': 'sex', 'p21022': 'age',\n",
    "                          'p20160_i0': 'ever_smoked',\n",
    "                          'p22006': 'ethnic_group',                           \n",
    "                          'p22019': 'sex_chromosome_aneuploidy',                          \n",
    "                          'p22021': 'kinship_to_other_participants'})\n",
    "# Add FID column -- required input format for regenie \n",
    "df_qced['FID'] = df_qced['IID']\n",
    "\n",
    "# Create a phenotype table from our QCed data\n",
    "df_phenotype = df_qced[['FID', 'IID', 'diabetes_cc', 'sex', 'age', 'ethnic_group', 'ever_smoked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phenotype = df_phenotype.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Select only samples that have WES data available and save them to CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get WES\n",
    "path_to_family_file = f'/mnt/project/Bulk/Exome sequences/{exome_folder}/ukb{exome_field_id}_c1_b0_v1.fam'\n",
    "plink_fam_df = pd.read_csv(path_to_family_file, delimiter='\\s', dtype='object',                           \n",
    "                           names = ['FID','IID','Father ID','Mother ID', 'sex', 'Pheno'], engine='python')\n",
    "# Intersect the phenotype file and the 200K WES .fam file\n",
    "# to generate phenotype DataFrame for the 200K participants\n",
    "diabetes_wes_200k_df = df_phenotype.join(plink_fam_df.set_index('IID'), on='IID', rsuffix='_fam', how='inner')\n",
    "# Drop unuseful columns from .fam file\n",
    "diabetes_wes_200k_df.drop(\n",
    "    columns=['FID_fam','Father ID','Mother ID','sex_fam', 'Pheno'], axis=1, inplace=True, errors='ignore'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write phenotype files to a TSV file\n",
    "diabetes_wes_200k_df.to_csv('diabetes_wes_200k.phe', sep='\\t', na_rep='NA', index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Load file to project storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$output_dir\"\n",
    "# Upload the geno-pheno intersect phenotype file back to the RAP project\n",
    "dx upload diabetes_wes_200k.phe -p --path $1 --brief"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of phenotype file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    |     FID |     IID |   diabetes_cc |   sex |   age |   ethnic_group |   ever_smoked |\n",
    "|---:|--------:|--------:|--------------:|------:|------:|---------------:|--------------:|\n",
    "|  1 | 1234567 | 1234567 |             1 |     0 |    67 |              1 |             0 |\n",
    "|  4 | 1234568 | 1234568 |             1 |     1 |    62 |              1 |             0 |\n",
    "|  6 | 1234569 | 1234569 |             0 |     1 |    50 |              1 |             1 |\n",
    "| 19 | 1234570 | 1234570 |             0 |     0 |    60 |              1 |             1 |\n",
    "| 20 | 1234571 | 1234571 |             0 |     1 |    58 |              1 |             0 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
